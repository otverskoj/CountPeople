{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q facenet_pytorch\n",
        "!pip install -q mmcv"
      ],
      "metadata": {
        "id": "Flp35KQs63A8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq7vLVUT61Zl"
      },
      "source": [
        "# Face tracking pipeline\n",
        "\n",
        "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "47_dD81S61Zn"
      },
      "outputs": [],
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import torch\n",
        "import numpy as np\n",
        "import mmcv, cv2\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFjlgW7q61Zo"
      },
      "source": [
        "#### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W2bS9J7p61Zo",
        "outputId": "a5f454a3-b96e-4c65-a698-71541dc45455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcrk-iV161Zp"
      },
      "source": [
        "#### Define MTCNN module\n",
        "\n",
        "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
        "\n",
        "See `help(MTCNN)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dHgCBmCY61Zp"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(keep_all=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_rAIZz661Zp"
      },
      "source": [
        "#### Get a sample video\n",
        "\n",
        "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5x5mpKd7QBk",
        "outputId": "00efd439-179d-404e-ad62-94ba0ca764c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "cEuzOccH61Zp"
      },
      "outputs": [],
      "source": [
        "# video = mmcv.VideoReader('/content/drive/MyDrive/video.mp4')\n",
        "# frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
        "\n",
        "# display.Video('/content/drive/MyDrive/video.mp4', width=640)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mmcv.cut_video('/content/drive/MyDrive/video.mp4', '/content/drive/MyDrive/clip.mp4', start=60, end=120, vcodec='h264')\n",
        "video = mmcv.VideoReader('/content/drive/MyDrive/clip.mp4')"
      ],
      "metadata": {
        "id": "tESQtZRwtzht"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-Xu6rB61Zq"
      },
      "source": [
        "#### Run video through MTCNN\n",
        "\n",
        "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames_tracked = []\n",
        "for i, frame in enumerate(video):\n",
        "\n",
        "    frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    print('\\rTracking frame: {}'.format(i + 1), end='')\n",
        "    \n",
        "    # Detect faces\n",
        "    boxes, _ = mtcnn.detect(frame)\n",
        "    \n",
        "    # Draw faces\n",
        "    frame_draw = frame.copy()\n",
        "    draw = ImageDraw.Draw(frame_draw)\n",
        "    if boxes is not None:\n",
        "        for box in boxes:\n",
        "            draw.rectangle(box.tolist(), outline=(255, 0, 0), width=6)\n",
        "    \n",
        "    # Add to frame list\n",
        "    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
        "print('\\nDone')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkHlT8Lxt8sf",
        "outputId": "23ccfcb0-9ae2-420f-808f-262451cdfc2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracking frame: 1500\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb1VjJxa61Zq"
      },
      "source": [
        "#### Display detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD7r0j1N61Zr"
      },
      "source": [
        "#### Save tracked video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jr5axYI561Zr"
      },
      "outputs": [],
      "source": [
        "dim = frames_tracked[0].size\n",
        "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
        "video_tracked = cv2.VideoWriter('/content/drive/MyDrive/video_tracked.mp4', fourcc, 25.0, dim)\n",
        "for frame in frames_tracked:\n",
        "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
        "video_tracked.release()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "simple_face_tracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}