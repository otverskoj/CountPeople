{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flp35KQs63A8",
        "outputId": "d17bd6d0-d1ea-46e7-9cc9-cd8226ecca81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 13.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 13.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 190 kB 47.6 MB/s \n",
            "\u001b[?25h  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q facenet_pytorch\n",
        "!pip install -q mmcv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq7vLVUT61Zl"
      },
      "source": [
        "# Face tracking pipeline\n",
        "\n",
        "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47_dD81S61Zn"
      },
      "outputs": [],
      "source": [
        "from facenet_pytorch import MTCNN\n",
        "import torch\n",
        "import numpy as np\n",
        "import mmcv, cv2\n",
        "from PIL import Image, ImageDraw\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFjlgW7q61Zo"
      },
      "source": [
        "#### Determine if an nvidia GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2bS9J7p61Zo",
        "outputId": "6fc1dd8d-f0e4-406e-c414-c974a5b86dba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Running on device: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcrk-iV161Zp"
      },
      "source": [
        "#### Define MTCNN module\n",
        "\n",
        "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
        "\n",
        "See `help(MTCNN)` for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHgCBmCY61Zp"
      },
      "outputs": [],
      "source": [
        "mtcnn = MTCNN(keep_all=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_rAIZz661Zp"
      },
      "source": [
        "#### Get a sample video\n",
        "\n",
        "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5x5mpKd7QBk",
        "outputId": "b247e810-8cf5-47e7-d11f-5b3815ecb590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEuzOccH61Zp",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# video = mmcv.VideoReader('/content/drive/MyDrive/video.mp4')\n",
        "# frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
        "\n",
        "# display.Video('/content/drive/MyDrive/video.mp4', width=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tESQtZRwtzht"
      },
      "outputs": [],
      "source": [
        "# mmcv.cut_video('/content/drive/MyDrive/video.mp4', '/content/drive/MyDrive/clip.mp4', start=60, end=120, vcodec='h264')\n",
        "video = mmcv.VideoReader('/content/drive/MyDrive/clip.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo-Xu6rB61Zq"
      },
      "source": [
        "#### Run video through MTCNN\n",
        "\n",
        "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYWtmHtv-y9V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "POINTS = np.array((\n",
        "    (250, 1440),\n",
        "    (515, 888), \n",
        "    (850, 450),\n",
        "    (1350, 450),\n",
        "    (1700, 600),\n",
        "    (2560, 600),\n",
        "    (2560, 1440),\n",
        "    (250, 1440)\n",
        "))\n",
        "\n",
        "\n",
        "def is_inside(point: np.ndarray, polygon: np.ndarray) -> bool:\n",
        "    in_polygon = False\n",
        "    x, y = point\n",
        "    for i in range(polygon.shape[0]):\n",
        "        curr_x, curr_y = polygon[i]\n",
        "        prev_x, prev_y = polygon[i - 1]\n",
        "        if ((curr_y <= y and y < prev_y) or (prev_y <= y and y < curr_y)) and \\\n",
        "           (x > (prev_x - curr_x) * (y - curr_y) / (prev_y - curr_y) + curr_x):\n",
        "                in_polygon = not in_polygon\n",
        "    return in_polygon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkHlT8Lxt8sf",
        "outputId": "ef401f02-d819-4b48-9a9a-ab672c623330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tracking frame: 1500\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "frames_tracked = []\n",
        "for i, frame in enumerate(video, start=1):\n",
        "\n",
        "    frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    print(f'\\rTracking frame: {i}', end='')\n",
        "    \n",
        "    # Detect faces\n",
        "    boxes, _ = mtcnn.detect(frame)\n",
        "    \n",
        "    # Draw faces\n",
        "    frame_draw = frame.copy()\n",
        "    drawer = ImageDraw.Draw(frame_draw)\n",
        "    if boxes is not None:\n",
        "        for box in boxes:\n",
        "            # up_left, down_right = box[:2], box[2:]\n",
        "            # if is_inside(up_left, points) and is_inside(down_right, points):\n",
        "            #     draw.rectangle(box.tolist(), outline=(255, 0, 0), width=6)\n",
        "            drawer.rectangle(box.tolist(), outline=(255, 0, 0), width=6)\n",
        "    \n",
        "    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
        "print('\\nDone')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb1VjJxa61Zq"
      },
      "source": [
        "#### Display detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD7r0j1N61Zr"
      },
      "source": [
        "#### Save tracked video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr5axYI561Zr"
      },
      "outputs": [],
      "source": [
        "dim = frames_tracked[0].size\n",
        "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
        "video_tracked = cv2.VideoWriter('/content/drive/MyDrive/video_tracked.mp4', fourcc, 25.0, dim)\n",
        "for frame in frames_tracked:\n",
        "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
        "video_tracked.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "simple_face_tracking.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
